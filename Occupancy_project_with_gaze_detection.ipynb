{"cells":[{"cell_type":"markdown","source":["# CSE5IDP Gartner Project by Agile Avengers"],"metadata":{"id":"yEUx10rY6yVH"}},{"cell_type":"markdown","source":["#### Run the below code to install and check YOLO"],"metadata":{"id":"IxdWx5157BVZ"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tdSMcABDNKW-","outputId":"f096f27c-751e-4305-f76c-0051ea0e8e65","executionInfo":{"status":"ok","timestamp":1732846654270,"user_tz":-660,"elapsed":33505,"user":{"displayName":"ansh rawat","userId":"08115511524876714999"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Ultralytics YOLOv8.0.196 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n","Setup complete âœ… (2 CPUs, 12.7 GB RAM, 32.6/107.7 GB disk)\n"]}],"source":["# Pip install method (recommended)\n","\n","!pip install ultralytics==8.0.196\n","\n","from IPython import display\n","display.clear_output()\n","\n","import ultralytics\n","ultralytics.checks()\n","\n","from ultralytics import YOLO\n","\n","from IPython.display import display, Image"]},{"cell_type":"markdown","source":["### Pre-requisite functions for gaze detection"],"metadata":{"id":"ZM_pKBk2x7Jv"}},{"cell_type":"code","source":["# Functions for gaze detection\n","import numpy as np\n","\n","# Function to calculate the midpoint between two points\n","def calculate_midpoint(point1, point2):\n","    return [(point1[0] + point2[0]) / 2, (point1[1] + point2[1]) / 2]\n","\n","def ray_intersection(p1, d1, p2, d2):\n","    \"\"\"\n","    Finds the intersection point of two rays if it exists.\n","    p1, d1: Starting point and direction vector of the first ray\n","    p2, d2: Starting point and direction vector of the second ray\n","    Returns the intersection point if it exists, otherwise None\n","    \"\"\"\n","    # Create vectors from points and directions\n","    p1, d1 = np.array(p1), np.array(d1)\n","    p2, d2 = np.array(p2), np.array(d2)\n","\n","    # Check if they are parallel by cross product\n","    cross_d1_d2 = np.cross(d1, d2)\n","    if np.isclose(cross_d1_d2, 0):  # Parallel or identical direction, no intersection\n","        return None\n","\n","    # Solving the parametric form of the lines\n","    t = np.cross(p2 - p1, d2) / cross_d1_d2\n","    u = np.cross(p2 - p1, d1) / cross_d1_d2\n","\n","    # Calculate the intersection point if t and u are positive (in forward direction)\n","    if t > 0 and u > 0:\n","        intersection_point = p1 + t * d1\n","        return intersection_point\n","    else:\n","        return None\n","\n","def calculate_inner_angle(d1, d2):\n","    \"\"\"\n","    Calculate the inner angle between two direction vectors\n","    d1, d2: Direction vectors of the rays\n","    Returns the inner angle in degrees\n","    \"\"\"\n","    # Normalize vectors\n","    d1 = d1 / np.linalg.norm(d1)\n","    d2 = d2 / np.linalg.norm(d2)\n","\n","    # Calculate angle using dot product, ensuring the inner angle\n","    dot_product = np.dot(d1, d2)\n","    angle = np.arccos(np.clip(dot_product, -1.0, 1.0))\n","    return np.degrees(angle)\n","\n","# Function to calculate the midpoint or use a single eye coordinate if only one is available\n","def get_eye_point(eye1, eye2):\n","    if np.all(eye1) and np.all(eye2):  # Check if both eye coordinates are available\n","        return [(eye1[0] + eye2[0]) / 2, (eye1[1] + eye2[1]) / 2]  # Midpoint of both eyes\n","    elif np.all(eye1):  # Use eye1 if only eye1 is available\n","        return eye1\n","    elif np.all(eye2):  # Use eye2 if only eye2 is available\n","        return eye2\n","    return None  # If both are missing, return None\n","\n","def check_if_in_group(person1, person2, angle_threshold=90):\n","    \"\"\"\n","    Determines if two rays form a group based on their intersection and angle\n","    ray1_start, ray1_point: Start and direction point for ray 1\n","    ray2_start, ray2_point: Start and direction point for ray 2\n","    angle_threshold: Threshold angle to consider the rays as a group\n","    \"\"\"\n","    # Extract nose and eye coordinates for both people\n","    nose1, eye1a, eye1b = person1[0], person1[1], person1[2]\n","    nose2, eye2a, eye2b = person2[0], person2[1], person2[2]\n","\n","    # Check if nose coordinates are available for both\n","    if not (np.all(nose1) and np.all(nose2)):\n","        print(\"Nose coordinate missing; cannot determine direction.\")\n","        return None\n","\n","    # Get eye points or midpoints for both people\n","    eye_point1 = get_eye_point(eye1a, eye1b)\n","    eye_point2 = get_eye_point(eye2a, eye2b)\n","\n","    # Check if eye points were successfully obtained\n","    if eye_point1 is None or eye_point2 is None:\n","        print(\"Eye coordinates missing; cannot determine direction.\")\n","        return None\n","\n","\n","    # Define direction vectors\n","    d1 = np.array(nose1) - np.array(eye_point1)\n","    d2 = np.array(nose2) - np.array(eye_point2)\n","\n","    # Check for intersection\n","    intersection_point = ray_intersection(eye_point1, d1, eye_point2, d2)\n","    if intersection_point is None:\n","        print(\"Rays do not intersect; not in a group.\")\n","        return False\n","\n","    # Calculate the inner angle\n","    inner_angle = calculate_inner_angle(d1, d2)\n","    print(f\"Intersection point: {intersection_point}\")\n","    print(f\"Inner angle between rays: {inner_angle} degrees\")\n","\n","    # Check if the inner angle is below the threshold\n","    if inner_angle < angle_threshold:\n","        print(\"The rays are in a group based on angle threshold.\")\n","        return True\n","    else:\n","        print(\"The rays are not in a group based on angle threshold.\")\n","        return False"],"metadata":{"id":"kLuXj65bv2Vs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### After running the above code once you can run the below code as many times you want using different or same pictures. Just make sure to change the image name and tune the hyper parameters accordingly."],"metadata":{"id":"bGP6ZaZcxfkt"}},{"cell_type":"code","source":["# Main source code\n","\n","import cv2\n","import numpy as np\n","from ultralytics import YOLO\n","from scipy.spatial import distance\n","import networkx as nx  # For graph and connected component analysis\n","\n","# Initialize YOLO model (replace 'yolov8n.pt' with the desired model)\n","model = YOLO('yolov8n.pt')\n","model_pose = YOLO('yolov8s-pose.pt')\n","\n","# Set the image path (replace 'test/9.jpeg' with your actual image)\n","image_path = 'test/5.jpg'\n","\n","# Perform detection on the image, only detecting class 0 (person)\n","results = model.predict(source=image_path, conf=0.4, classes=0, save=True)\n","\n","# Perform pose detection for keypoints\n","results_pose = model_pose(image_path, save = True)\n","\n","# Load the image for visualization\n","image = cv2.imread(image_path)\n","\n","# Initialize lists to store bounding box centers, coordinates, and areas\n","bbox_centers = []\n","bbox_coords = []\n","bbox_areas = []\n","first_three_keypoints = []\n","\n","\n","# Iterate over each detection result\n","for result in results:\n","    boxes = result.boxes.xyxy.cpu().numpy()  # Bounding box coordinates\n","    confidences = result.boxes.conf.cpu().numpy()  # Confidence scores\n","    class_ids = result.boxes.cls.cpu().numpy()  # Class ids (people in this case)\n","\n","    # Draw bounding boxes around detected people\n","    for i, box in enumerate(boxes):\n","        x_min, y_min, x_max, y_max = box.astype(int)\n","        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)  # Green bounding box for person\n","        print(f\"Person detected: Bounding Box Coordinates: {box}, Confidence: {confidences[i]}, Class ID: {class_ids[i]}\")\n","\n","        # Compute the center and area of the bounding box\n","        center_x = (x_min + x_max) // 2\n","        center_y = (y_min + y_max) // 2\n","        area = (x_max - x_min) * (y_max - y_min)\n","\n","        bbox_centers.append([center_x, center_y])\n","        bbox_coords.append([x_min, y_min, x_max, y_max])\n","        bbox_areas.append(area)  # Keep track of bounding box area\n","\n","# Extract first 3 keypoints for each person and plot them\n","for result in results_pose:\n","    if hasattr(result, 'keypoints') and result.keypoints is not None:\n","        keypoints = result.keypoints.data.cpu().numpy()\n","        # Get the first 3 keypoints (x, y only) for each person and plot\n","        for person_keypoints in keypoints:\n","            person_first_three = []\n","            for idx, (x, y, _) in enumerate(person_keypoints[:3]):  # Only use the first three keypoints\n","                cv2.circle(image, (int(x), int(y)), 3, (0, 0, 255), -1)  # Red dot for keypoints\n","                person_first_three.append([x, y])\n","            first_three_keypoints.append(person_first_three)\n","\n","# Convert bbox_centers to a numpy array\n","bbox_centers = np.array(bbox_centers)\n","first_three_keypoints = np.array(first_three_keypoints)\n","\n","\n","# Parameters to tune\n","min_distance = 50      # Minimum distance between people to be considered in the same group\n","max_distance = 200     # Maximum distance threshold for grouping\n","area_threshold_ratio = 0.5  # Bounding box area ratio threshold for distance-based grouping\n","\n","# Step 1: Graph Construction\n","# Create a graph where each node is a person, and edges exist between people within the distance threshold\n","G = nx.Graph()\n","for i in range(len(bbox_centers)):\n","    G.add_node(i)\n","\n","# Add edges between people who are close enough (within social distance constraints) and similar in size\n","for i in range(len(bbox_centers)):\n","    for j in range(i + 1, len(bbox_centers)):\n","        # Compute centroid distance\n","        dist = distance.euclidean(bbox_centers[i], bbox_centers[j])\n","\n","        # Calculate area ratio\n","        area_ratio = min(bbox_areas[i], bbox_areas[j]) / max(bbox_areas[i], bbox_areas[j])\n","\n","        # Check if both distance and area ratio meet the thresholds\n","        if min_distance <= dist <= max_distance and area_ratio >= area_threshold_ratio:\n","            result = check_if_in_group(first_three_keypoints[i], first_three_keypoints[j], angle_threshold=90)\n","            if result is not False:  # Add edge if result is not explicitly False\n","                G.add_edge(i, j)\n","\n","\n","# Step 2: Find Connected Components (Groups)\n","connected_components = list(nx.connected_components(G))\n","\n","# Step 3: Filter out single-person groups\n","group_components = [group for group in connected_components if len(group) > 1]\n","\n","# Step 4: Visualize groups (Draw bounding boxes around groups)\n","for group in group_components:\n","    group_indices = list(group)\n","\n","    # Get bounding box coordinates for all people in the group\n","    group_x_min = min(bbox_coords[idx][0] for idx in group_indices)\n","    group_y_min = min(bbox_coords[idx][1] for idx in group_indices)\n","    group_x_max = max(bbox_coords[idx][2] for idx in group_indices)\n","    group_y_max = max(bbox_coords[idx][3] for idx in group_indices)\n","\n","    # Draw a larger bounding box around the group\n","    cv2.rectangle(image, (group_x_min, group_y_min), (group_x_max, group_y_max), (255, 0, 0), 3)  # Blue bounding box for group\n","\n","# Density-based methods: Create a density heatmap based on person locations\n","def create_density_heatmap(bbox_centers, image_shape, sigma=15):\n","    heatmap = np.zeros((image_shape[0], image_shape[1]), dtype=np.float32)\n","\n","    for center in bbox_centers:\n","        x, y = int(center[0]), int(center[1])\n","        heatmap[y, x] += 1  # Increment heatmap at each person's location\n","\n","    heatmap = cv2.GaussianBlur(heatmap, (0, 0), sigma)\n","    heatmap = cv2.normalize(heatmap, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n","    heatmap_colored = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n","\n","    return heatmap_colored\n","\n","# Generate heatmap\n","image_shape = image.shape[:2]\n","heatmap = create_density_heatmap(bbox_centers, image_shape)\n","\n","# Save and display the final output with both individual and group bounding boxes\n","cv2.imwrite('group_detection_output.jpg', image)\n","cv2.imwrite('density_heatmap.jpg', heatmap)\n","\n","# Draw all detected pose points on the final output image\n","for result in results_pose:\n","    if hasattr(result, 'keypoints') and result.keypoints is not None:\n","        keypoints = result.keypoints.data.cpu().numpy()\n","\n","        for person_keypoints in keypoints:\n","            # Loop through all keypoints for this person and draw them on the image\n","            for (x, y, _) in person_keypoints:\n","                x, y = int(x), int(y)\n","                cv2.circle(image, (x, y), 5, (0, 0, 255), -1)  # Red dots for keypoints with increased size\n","\n","# Save and display the final output with bounding boxes and keypoints\n","cv2.imwrite('group_detection_output_with_keypoints.jpg', image)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yjV1LHtx9CjK","outputId":"7d715b6d-7a9c-40a6-ccb3-a507086d11f8","executionInfo":{"status":"ok","timestamp":1732847107454,"user_tz":-660,"elapsed":1831,"user":{"displayName":"ansh rawat","userId":"08115511524876714999"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/test/1.jpeg: 288x640 8 persons, 117.0ms\n","Speed: 2.0ms preprocess, 117.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n","Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Person detected: Bounding Box Coordinates: [     854.24      131.08      992.27       472.2], Confidence: 0.8006943464279175, Class ID: 0.0\n","Person detected: Bounding Box Coordinates: [     495.21      144.98      624.65       454.4], Confidence: 0.7956050038337708, Class ID: 0.0\n","Person detected: Bounding Box Coordinates: [     745.91      126.59       885.6      484.88], Confidence: 0.743084728717804, Class ID: 0.0\n","Person detected: Bounding Box Coordinates: [     346.73      163.74      396.99      360.07], Confidence: 0.7022331357002258, Class ID: 0.0\n","Person detected: Bounding Box Coordinates: [      211.4      114.76      357.62      403.85], Confidence: 0.5746599435806274, Class ID: 0.0\n","Person detected: Bounding Box Coordinates: [     184.18      194.09      320.98      430.19], Confidence: 0.5475128889083862, Class ID: 0.0\n","Person detected: Bounding Box Coordinates: [     213.11      115.09      356.87      296.37], Confidence: 0.4261578619480133, Class ID: 0.0\n","Person detected: Bounding Box Coordinates: [     540.76      178.04       742.5      467.04], Confidence: 0.41901248693466187, Class ID: 0.0\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}